{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basis ML\n",
    "  \n",
    "In deze cursus zullen we de basis principes van Machine Learning belichten en bespreken. \n",
    "We zullen verschillende topics licht aanraken en hopen een holistisch beeld te kunnen schetsen\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit zijn de onderwerpen die we gaan bekijken.\n",
    "<p>&nbsp;</p> \n",
    " \n",
    "* EDA  \n",
    "* Data Cleaning\n",
    "* Feature engineering\n",
    "* Modellen trainen en selecteren\n",
    "* Modellen tunen\n",
    "* Modellen in productie\n",
    "* Cloud en Spark\n",
    "\n",
    "\n",
    "Deze cursus is gemaakt met jupyter notebooks. Jupyter notebooks worden veel gebruikt door data scientist om eerste prototypes in te maken. Notebooks zijn gebaseerd op de principes van het literal programming. Notebooks combineren documentatie met uit te voerden code. \n",
    "<p>&nbsp;</p> \n",
    "Deze cursus kan jedus zowel als website bekeken worden maar alle code examples kunnen ook uitgevoerd worden door de colab button uit te voeren.\n",
    "<p>&nbsp;</p> \n",
    "Hieronder een voorbeeld van een code cell die uitgevoerd kan worden.\n",
    "<p>&nbsp;</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Via de execute knop bovenaan kan je deze cursus openen op een interactieve omgeving zoals Google Colab uitvoeren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Toepassingen\n",
    "\n",
    "Wat zijn ML toepassingen nu juist? Stel we moeten inschatten hoeveel tijd een verhuis gaat kosten. Op voorhand kunnen we regels gaan opstellen en schatten hoeveel tijd we per item gaan nodig hebben. Bij traditionele software schrijven we meestal het volgende.\n",
    "<p>&nbsp;</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cost(num_bedrooms,num_bathrooms,sq_ft):\n",
    "    if num_bedrooms == 2 and num_bathrooms == 2:\n",
    "        return 1500\n",
    "    elif num_bedrooms == 3 and sq_ft > 2000:\n",
    "        return 2500\n",
    "    return 2000\n",
    "\n",
    "\n",
    "cost(2,3,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien wel snel dat bij het vergroten van de inpout parameters dat deze if else structuren snel zeer onoverzichtelijk beginnen te worden. ML laat ons toe om deze if else structuren te vervangen door modellen die we kunnen trainen op historische data. We gaan als het ware de if else leren uit het verleden. Bij het leren een toepassen van deze technieken komt wel heel wat te kijken. We zullen nu even de grote lijnen toelichten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "Het hoofdoel van EDA is om je historische data die je wil gebruiken bij het trainen te leren kennen. Zodoende vroeg in het process al eventueel zaken te detecteren die het latere verloop zullen bemoeilijken. Typisch kijken we naar missing values. Data distributies. Correlaties tussen verschillende features. Na deze stap begrijpen we onze data beter en kunnen we de volgende stappen gaan definieren. Eventueel kunnen we ook al beslissen dat extra data nodig is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning  \n",
    "\n",
    "Wat doen we met missing values? Laten we volledige kolomen weg of gaan we waardes trachten te gokken. Distributies die niet normaal verdeeld zijn gaan we deze proberen te transformeren. Sommige ML modellen zijn zeer gevoelig aan data distributies en kunnen vreemd gedrag vertonen als we hier geen rekening mee gaan houden. De data cleaning stap is de voorbereidened stap waar we hier rekening mee gaan houden. Eventueel kunnen we ook outliers gaan detecteren en proberen te verwijderen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "We hebben onze data ondertussen leren kennen en we hebben de data in een behapbare vorm gekregen. Nu kunnen we eens kijken samen met de domein experten welke features we best gaan gebruiken. Kunnen we met de huidige features set misschien nog extra features gaan berekenen of afleiden. Als we geospatiale informatie hebben dan kunnen we misschien extra aggregaties gaan toevoegen. Als we tijdsgebonden data hebben kunnen we de tijd gaan transformeren naar meer ML toegankelijkere formaten. Dit zijn allemaal stappen die we tijden deze fase gaan uitvoeren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellen trainen en selecteren\n",
    "\n",
    "De data is nu klaar en we kunnen nu onze modellen gaan trainen. We zoeken via een iteratief process de parameters van onze modellen. Er zijn veel verschillende modellen die we kunnen trainen. Hier beperken we ons vooral tot liniaire modellen en decision trees. Belangrijk om ook te bepalen is op welke metric ons model geoptimaliseerd wordt. Er bestaan low code libraries die bij een eerste selectie kunnen helpen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellen tunen\n",
    "\n",
    "Eens we via selectie methode model kandidaten hebben gevonden dan kunnen we modellen verder gaan tunen. Die door de hyperparameters wat beter te gaan afstellen of door combinaties te gaan maken van verschillende modellen. We moeten ook rekening beginnen te gaan houden met overfitting willen we de bruikbaarheid van onze modellen op nieuwe data kunnen garanderen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellen in productie\n",
    "\n",
    "Als we modellen in productie zetten moeten we rekening houden met verschillende aspecten. Is de nieuwe data die we gaan voorspellen gelijkaardig aan de historisch data. Hoe betrouwbaar is ons model op termijn. Op welke tijdstippen gaan we de modellen opnieuw gaan trainen? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud en Spark\n",
    "\n",
    "Welke zijn de courante componenten ter ondersteuning van een ML Project"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
